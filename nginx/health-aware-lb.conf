# Health-aware load balancer configuration for AUSTA Cockpit
# This configuration integrates with health checks for intelligent routing

upstream ai_service_backend {
    # Enable health checks for AI service
    least_conn;
    
    # AI service instances with health checks
    server ai-service-1:8000 max_fails=3 fail_timeout=30s;
    server ai-service-2:8000 max_fails=3 fail_timeout=30s;
    server ai-service-3:8000 max_fails=3 fail_timeout=30s;
    
    # Backup server in case all primary servers fail
    server ai-service-backup:8000 backup;
    
    # Health check configuration
    keepalive 32;
    keepalive_requests 100;
    keepalive_timeout 60s;
}

upstream backend_api {
    # Enable health checks for backend API
    least_conn;
    
    # Backend service instances
    server backend-service-1:3000 max_fails=3 fail_timeout=30s;
    server backend-service-2:3000 max_fails=3 fail_timeout=30s;
    server backend-service-3:3000 max_fails=3 fail_timeout=30s;
    
    # Backup server
    server backend-service-backup:3000 backup;
    
    keepalive 32;
    keepalive_requests 100;
    keepalive_timeout 60s;
}

upstream frontend_web {
    # Frontend service instances
    least_conn;
    
    server frontend-service-1:80 max_fails=2 fail_timeout=10s;
    server frontend-service-2:80 max_fails=2 fail_timeout=10s;
    
    keepalive 16;
}

# Rate limiting zones
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
limit_req_zone $binary_remote_addr zone=health_limit:10m rate=1r/s;

# Connection limiting
limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

server {
    listen 80;
    server_name austa-cockpit.local;
    
    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    
    # Connection limits
    limit_conn conn_limit 10;
    
    # Access logging with health check filtering
    access_log /var/log/nginx/access.log combined if=$not_health_check;
    error_log /var/log/nginx/error.log warn;
    
    # Define health check requests to avoid logging noise
    map $request_uri $not_health_check {
        ~^/health      0;
        ~^/api/health  0;
        ~^/ai/health   0;
        default        1;
    }
    
    # Main frontend application
    location / {
        proxy_pass http://frontend_web;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Health check for frontend
        proxy_next_upstream error timeout invalid_header http_502 http_503 http_504;
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 10s;
        
        # Cache static assets
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff2)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
    
    # Backend API with intelligent routing
    location /api/ {
        # Rate limiting
        limit_req zone=api_limit burst=20 nodelay;
        
        proxy_pass http://backend_api;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Enhanced health check behavior
        proxy_next_upstream error timeout invalid_header http_502 http_503 http_504;
        proxy_connect_timeout 10s;
        proxy_send_timeout 30s;
        proxy_read_timeout 30s;
        
        # Retry on upstream failures
        proxy_next_upstream_tries 3;
        proxy_next_upstream_timeout 60s;
        
        # Circuit breaker simulation with error pages
        error_page 502 503 504 @backend_unavailable;
    }
    
    # AI service with special handling for model inference
    location /ai/ {
        # Higher rate limit for AI endpoints
        limit_req zone=api_limit burst=5 nodelay;
        
        proxy_pass http://ai_service_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Longer timeouts for AI processing
        proxy_connect_timeout 15s;
        proxy_send_timeout 120s;  # AI inference can take time
        proxy_read_timeout 120s;
        
        # Health-aware upstream selection
        proxy_next_upstream error timeout invalid_header http_502 http_503 http_504;
        proxy_next_upstream_tries 2;  # Fewer retries for AI to avoid cascading delays
        proxy_next_upstream_timeout 180s;
        
        # Special handling for model inference endpoints
        location ~ ^/ai/(analyze|predict|inference) {
            # Even longer timeouts for inference
            proxy_read_timeout 300s;
            proxy_send_timeout 300s;
            
            # Buffer large requests/responses
            proxy_buffering on;
            proxy_buffer_size 64k;
            proxy_buffers 8 64k;
            client_max_body_size 10M;
        }
        
        error_page 502 503 504 @ai_unavailable;
    }
    
    # Health check endpoints with special handling
    location /health {
        # Limited rate for health checks
        limit_req zone=health_limit burst=5 nodelay;
        
        # Internal health check
        access_log off;
        
        # Custom health check logic
        content_by_lua_block {
            local http = require "resty.http"
            local httpc = http.new()
            
            -- Check backend health
            local backend_res, backend_err = httpc:request_uri("http://backend-service:3000/health", {
                method = "GET",
                timeout = 5000,
            })
            
            -- Check AI service health
            local ai_res, ai_err = httpc:request_uri("http://ai-service:8000/health", {
                method = "GET", 
                timeout = 5000,
            })
            
            local status = "healthy"
            local details = {}
            
            if not backend_res or backend_res.status ~= 200 then
                status = "degraded"
                details.backend = "unhealthy"
            else
                details.backend = "healthy"
            end
            
            if not ai_res or ai_res.status ~= 200 then
                status = "degraded"
                details.ai_service = "unhealthy"
            else
                details.ai_service = "healthy"
            end
            
            if details.backend == "unhealthy" and details.ai_service == "unhealthy" then
                status = "unhealthy"
                ngx.status = 503
            elseif status == "degraded" then
                ngx.status = 200
            else
                ngx.status = 200
            end
            
            ngx.header.content_type = "application/json"
            ngx.say(require("cjson").encode({
                status = status,
                timestamp = ngx.time(),
                services = details,
                load_balancer = "healthy"
            }))
        }
    }
    
    # Advanced health check with service discovery integration
    location /health/detailed {
        access_log off;
        
        content_by_lua_block {
            local http = require "resty.http"
            local httpc = http.new()
            local cjson = require "cjson"
            
            local services = {
                {name = "backend", url = "http://backend-service:3000/health/detailed"},
                {name = "ai-service", url = "http://ai-service:8000/health/detailed"},
                {name = "frontend", url = "http://frontend-service:80/health"}
            }
            
            local results = {}
            local overall_healthy = true
            local critical_count = 0
            
            for _, service in ipairs(services) do
                local res, err = httpc:request_uri(service.url, {
                    method = "GET",
                    timeout = 10000,
                })
                
                if res and res.status == 200 then
                    local success, data = pcall(cjson.decode, res.body)
                    if success then
                        results[service.name] = {
                            status = "healthy",
                            response_time = res.elapsed or 0,
                            data = data
                        }
                    else
                        results[service.name] = {
                            status = "healthy",
                            response_time = res.elapsed or 0,
                            raw_response = res.body
                        }
                    end
                else
                    results[service.name] = {
                        status = "unhealthy",
                        error = err or "HTTP " .. (res and res.status or "error")
                    }
                    overall_healthy = false
                    critical_count = critical_count + 1
                end
            end
            
            local final_status
            if critical_count >= 2 then
                final_status = "unhealthy"
                ngx.status = 503
            elseif critical_count == 1 then
                final_status = "degraded"
                ngx.status = 200
            else
                final_status = "healthy"
                ngx.status = 200
            end
            
            ngx.header.content_type = "application/json"
            ngx.say(cjson.encode({
                overall_status = final_status,
                timestamp = ngx.time(),
                services = results,
                load_balancer = {
                    status = "healthy",
                    upstream_stats = {
                        backend_api = "Available",
                        ai_service_backend = "Available", 
                        frontend_web = "Available"
                    }
                },
                critical_services_down = critical_count
            }))
        }
    }
    
    # Kubernetes-style health probes
    location /healthz {
        access_log off;
        return 200 "OK\n";
        add_header Content-Type text/plain;
    }
    
    location /readiness {
        access_log off;
        
        # Check if upstreams are available
        content_by_lua_block {
            local available_backends = 0
            local available_ai = 0
            
            -- Simple TCP check would go here
            -- For now, return ready if we can bind to the upstream
            
            if available_backends > 0 and available_ai > 0 then
                ngx.status = 200
                ngx.say("Ready")
            else
                ngx.status = 503
                ngx.say("Not Ready")
            end
        }
    }
    
    # Error pages for service unavailability
    location @backend_unavailable {
        internal;
        
        default_type application/json;
        return 503 '{"error": "Backend service temporarily unavailable", "retry_after": 30, "timestamp": "$time_iso8601"}';
    }
    
    location @ai_unavailable {
        internal;
        
        default_type application/json;
        return 503 '{"error": "AI service temporarily unavailable", "message": "Model inference is currently unavailable. Please try again later.", "retry_after": 60, "timestamp": "$time_iso8601"}';
    }
    
    # Status page for monitoring
    location /nginx_status {
        stub_status on;
        access_log off;
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
    }
}

# SSL/TLS configuration
server {
    listen 443 ssl http2;
    server_name austa-cockpit.local;
    
    # SSL configuration
    ssl_certificate /etc/ssl/certs/austa-cockpit.crt;
    ssl_certificate_key /etc/ssl/private/austa-cockpit.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    # Health checks over HTTPS
    location /health {
        # Same health check logic as HTTP
        limit_req zone=health_limit burst=5 nodelay;
        access_log off;
        
        proxy_pass http://127.0.0.1:80/health;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-Proto https;
    }
    
    # Redirect other traffic to HTTP for now (can be changed based on requirements)
    location / {
        return 301 http://$server_name$request_uri;
    }
}