input {
  # Application logs from Docker containers
  beats {
    port => 5044
  }
  
  # Direct TCP input for structured logs
  tcp {
    port => 5000
    codec => json_lines
  }
  
  # UDP input for syslog
  udp {
    port => 5000
    codec => json_lines
  }
  
  # HTTP input for webhooks and API logs
  http {
    port => 8080
    codec => json
  }
}

filter {
  # Parse application logs
  if [fields][app] == "austa-backend" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} %{GREEDYDATA:message}" }
    }
    
    mutate {
      add_field => { "service" => "backend" }
      add_field => { "environment" => "production" }
    }
  }
  
  # Parse AI service logs
  if [fields][app] == "austa-ai-service" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{DATA:logger} %{GREEDYDATA:message}" }
    }
    
    mutate {
      add_field => { "service" => "ai-service" }
      add_field => { "environment" => "production" }
    }
  }
  
  # Parse frontend logs
  if [fields][app] == "austa-frontend" {
    json {
      source => "message"
    }
    
    mutate {
      add_field => { "service" => "frontend" }
      add_field => { "environment" => "production" }
    }
  }
  
  # Parse security logs
  if [fields][logtype] == "security" {
    json {
      source => "message"
    }
    
    mutate {
      add_field => { "log_type" => "security" }
    }
    
    # Enrich security events
    if [event_type] == "failed_login" {
      mutate {
        add_field => { "alert_level" => "warning" }
      }
    }
    
    if [event_type] == "suspicious_activity" {
      mutate {
        add_field => { "alert_level" => "critical" }
      }
    }
  }
  
  # Parse database logs
  if [fields][app] == "postgres" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{DATA:timezone} %{DATA:username} %{DATA:database} %{DATA:pid} %{LOGLEVEL:level}: %{GREEDYDATA:message}" }
    }
    
    mutate {
      add_field => { "service" => "database" }
    }
  }
  
  # Parse performance logs
  if [fields][logtype] == "performance" {
    json {
      source => "message"
    }
    
    # Extract performance metrics
    if [response_time] {
      mutate {
        convert => { "response_time" => "float" }
      }
      
      if [response_time] > 2.0 {
        mutate {
          add_field => { "performance_alert" => "slow_response" }
        }
      }
    }
  }
  
  # Common enrichment
  mutate {
    add_field => { "[@metadata][index]" => "austa-logs-%{+YYYY.MM.dd}" }
  }
  
  # Remove unwanted fields
  mutate {
    remove_field => [ "beat", "input", "agent", "ecs", "host" ]
  }
  
  # Convert timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index]}"
    template_name => "austa-logs"
    template => "/usr/share/logstash/templates/austa-logs-template.json"
    template_overwrite => true
  }
  
  # Debug output (remove in production)
  stdout {
    codec => rubydebug
  }
  
  # Send critical alerts to external systems
  if [alert_level] == "critical" {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "alerts" => [{
          "labels" => {
            "alertname" => "LogAlert"
            "severity" => "critical"
            "service" => "%{service}"
            "log_type" => "%{log_type}"
          }
          "annotations" => {
            "summary" => "Critical log event detected"
            "description" => "%{message}"
          }
          "startsAt" => "%{@timestamp}"
        }]
      }
    }
  }
}