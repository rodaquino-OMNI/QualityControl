name: Production Deployment Pipeline

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      force_deploy:
        description: 'Force deployment even if tests fail'
        required: false
        type: boolean
        default: false

env:
  REGISTRY: ghcr.io
  NODE_VERSION: '20.x'
  PYTHON_VERSION: '3.11'
  KUBERNETES_VERSION: 'v1.28.0'

jobs:
  # Test Stage - Parallel execution for all services
  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    outputs:
      cache-hit: ${{ steps.cache.outputs.cache-hit }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Cache dependencies
      id: cache
      uses: actions/cache@v3
      with:
        path: |
          frontend/node_modules
          ~/.npm
        key: frontend-${{ runner.os }}-${{ hashFiles('frontend/package-lock.json') }}
        restore-keys: |
          frontend-${{ runner.os }}-

    - name: Install dependencies
      if: steps.cache.outputs.cache-hit != 'true'
      working-directory: ./frontend
      run: npm ci

    - name: Run ESLint
      working-directory: ./frontend
      run: npm run lint

    - name: Run TypeScript check
      working-directory: ./frontend
      run: npm run typecheck

    - name: Run unit tests
      working-directory: ./frontend
      run: npm run test:coverage

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: frontend-test-results
        path: |
          frontend/coverage/
          frontend/test-results.xml

  test-backend:
    name: Test Backend
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: austa_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: backend/package-lock.json

    - name: Install dependencies
      working-directory: ./backend
      run: npm ci

    - name: Run database migrations
      working-directory: ./backend
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/austa_test
      run: npx prisma migrate deploy

    - name: Run ESLint
      working-directory: ./backend
      run: npm run lint

    - name: Run TypeScript check
      working-directory: ./backend
      run: npm run typecheck

    - name: Run tests
      working-directory: ./backend
      env:
        NODE_ENV: test
        DATABASE_URL: postgresql://test:test@localhost:5432/austa_test
        REDIS_URL: redis://localhost:6379
        JWT_SECRET: test-secret
      run: npm run test:coverage

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: backend-test-results
        path: |
          backend/coverage/
          backend/test-results.xml

  test-ai-service:
    name: Test AI Service
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: ai_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        cache-dependency-path: ai-service/requirements*.txt

    - name: Install dependencies
      working-directory: ./ai-service
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run linting
      working-directory: ./ai-service
      run: |
        flake8 app tests
        black --check app tests
        isort --check-only app tests

    - name: Run type checking
      working-directory: ./ai-service
      run: mypy app

    - name: Run tests
      working-directory: ./ai-service
      env:
        ENVIRONMENT: test
        DATABASE_URL: postgresql://test:test@localhost:5432/ai_test
        REDIS_URL: redis://localhost:6379/15
        JWT_SECRET: test-secret
        OPENAI_API_KEY: test-key
      run: pytest -v --cov=app --cov-report=xml --cov-report=html

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: ai-service-test-results
        path: |
          ai-service/coverage.xml
          ai-service/htmlcov/

  # Security Scan Stage
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [test-frontend, test-backend, test-ai-service]
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH,MEDIUM'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Setup Node.js for audit
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Run npm audit for frontend
      working-directory: ./frontend
      run: |
        npm audit --audit-level=high --production || true
        npm audit --json --production > ../frontend-audit.json || true

    - name: Run npm audit for backend
      working-directory: ./backend
      run: |
        npm audit --audit-level=high --production || true
        npm audit --json --production > ../backend-audit.json || true

    - name: Setup Python for security scan
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Run Python security scan
      working-directory: ./ai-service
      run: |
        pip install bandit safety
        bandit -r app -f json -o ../bandit-report.json || true
        safety check --json --output ../safety-report.json || true

    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          trivy-results.sarif
          frontend-audit.json
          backend-audit.json
          bandit-report.json
          safety-report.json

  # Build Stage - Docker images
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [test-frontend, test-backend, test-ai-service, security-scan]
    if: ${{ !failure() || inputs.force_deploy }}
    strategy:
      matrix:
        service: [frontend, backend, ai-service]
    outputs:
      frontend-image: ${{ steps.meta.outputs.tags }}
      backend-image: ${{ steps.meta.outputs.tags }}
      ai-service-image: ${{ steps.meta.outputs.tags }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile.${{ matrix.service }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

    - name: Generate SBOM
      uses: anchore/sbom-action@v0
      with:
        image: ${{ steps.meta.outputs.tags }}
        format: spdx-json
        output-file: /tmp/sbom-${{ matrix.service }}.spdx.json

    - name: Upload SBOM
      uses: actions/upload-artifact@v3
      with:
        name: sbom-${{ matrix.service }}
        path: /tmp/sbom-${{ matrix.service }}.spdx.json

  # Database Migration Stage
  migrate-database:
    name: Database Migration
    runs-on: ubuntu-latest
    needs: [build-images]
    if: ${{ github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v') }}
    environment: 
      name: ${{ inputs.environment || 'staging' }}
      url: ${{ steps.deploy.outputs.url }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4  
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Install backend dependencies
      working-directory: ./backend
      run: npm ci --production

    - name: Run database migrations
      working-directory: ./backend
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
      run: |
        echo "Running database migrations..."
        npx prisma migrate deploy
        echo "Database migrations completed successfully"

    - name: Verify database schema
      working-directory: ./backend
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
      run: |
        npx prisma db pull --print
        echo "Database schema verification completed"

  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [migrate-database]
    if: ${{ github.ref == 'refs/heads/main' || inputs.environment == 'staging' }}
    environment:
      name: staging
      url: https://staging.austa-cockpit.com
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Kubernetes CLI
      uses: azure/setup-kubectl@v3
      with:
        version: ${{ env.KUBERNETES_VERSION }}

    - name: Setup Helm
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Configure kubectl
      env:
        KUBE_CONFIG: ${{ secrets.KUBE_CONFIG_STAGING }}
      run: |
        mkdir -p ~/.kube
        echo "$KUBE_CONFIG" | base64 -d > ~/.kube/config
        chmod 600 ~/.kube/config

    - name: Deploy to staging with Helm
      env:
        HELM_REGISTRY_CONFIG: ${{ secrets.HELM_REGISTRY_CONFIG }}
      run: |
        helm upgrade --install austa-staging ./helm/austa-cockpit \
          --namespace staging \
          --create-namespace \
          --values ./helm/austa-cockpit/values-staging.yaml \
          --set image.tag=${{ github.sha }} \
          --set frontend.image.repository=${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-frontend \
          --set backend.image.repository=${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-backend \
          --set aiService.image.repository=${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-ai-service \
          --timeout 10m \
          --wait

    - name: Run smoke tests
      run: |
        echo "Running smoke tests against staging environment..."
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=austa-staging -n staging --timeout=300s
        kubectl port-forward svc/austa-staging-frontend 8080:80 -n staging &
        sleep 30
        curl -f http://localhost:8080/health || exit 1
        echo "Smoke tests passed"

    - name: Post deployment notification
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        fields: repo,message,commit,author,action,eventName,ref,workflow

  # Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: ${{ startsWith(github.ref, 'refs/tags/v') || inputs.environment == 'production' }}
    environment:
      name: production
      url: https://austa-cockpit.com
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Kubernetes CLI
      uses: azure/setup-kubectl@v3
      with:
        version: ${{ env.KUBERNETES_VERSION }}

    - name: Setup Helm
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Configure kubectl
      env:
        KUBE_CONFIG: ${{ secrets.KUBE_CONFIG_PRODUCTION }}
      run: |
        mkdir -p ~/.kube
        echo "$KUBE_CONFIG" | base64 -d > ~/.kube/config
        chmod 600 ~/.kube/config

    - name: Create backup before deployment
      run: |
        echo "Creating backup before production deployment..."
        kubectl create job backup-$(date +%Y%m%d-%H%M%S) \
          --from=cronjob/backup-job -n production || true

    - name: Blue-Green Deployment
      env:
        HELM_REGISTRY_CONFIG: ${{ secrets.HELM_REGISTRY_CONFIG }}
      run: |
        # Deploy to green environment
        helm upgrade --install austa-green ./helm/austa-cockpit \
          --namespace production \
          --values ./helm/austa-cockpit/values-production.yaml \
          --set image.tag=${{ github.sha }} \
          --set frontend.image.repository=${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-frontend \
          --set backend.image.repository=${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-backend \
          --set aiService.image.repository=${{ env.REGISTRY }}/${{ github.repository_owner }}/austa-ai-service \
          --set deployment.color=green \
          --timeout 15m \
          --wait

    - name: Health check on green deployment
      run: |
        echo "Running health checks on green deployment..."
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=austa-green -n production --timeout=600s
        
        # Port forward and test green deployment
        kubectl port-forward svc/austa-green-frontend 8080:80 -n production &
        PF_PID=$!
        sleep 30
        
        # Run comprehensive health checks
        curl -f http://localhost:8080/health || exit 1
        curl -f http://localhost:8080/api/health || exit 1
        curl -f http://localhost:8080/ai/health || exit 1
        
        kill $PF_PID
        echo "Green deployment health checks passed"

    - name: Switch traffic to green (Blue-Green cutover)
      run: |
        echo "Switching traffic to green deployment..."
        # Update ingress to point to green deployment
        kubectl patch ingress austa-ingress -n production -p '{"spec":{"rules":[{"http":{"paths":[{"path":"/","pathType":"Prefix","backend":{"service":{"name":"austa-green-frontend","port":{"number":80}}}}]}}]}}'
        
        # Wait for ingress update
        sleep 60
        
        # Verify traffic is flowing to green
        curl -f https://austa-cockpit.com/health || exit 1

    - name: Remove blue deployment
      run: |
        echo "Removing old blue deployment..."
        helm uninstall austa-blue -n production || true
        
        # Rename green to blue for next deployment
        kubectl patch deployment austa-green-frontend -n production -p '{"metadata":{"labels":{"app.kubernetes.io/instance":"austa-blue"}}}'
        kubectl patch deployment austa-green-backend -n production -p '{"metadata":{"labels":{"app.kubernetes.io/instance":"austa-blue"}}}'
        kubectl patch deployment austa-green-ai-service -n production -p '{"metadata":{"labels":{"app.kubernetes.io/instance":"austa-blue"}}}'

    - name: Post deployment verification
      run: |
        echo "Running post-deployment verification..."
        kubectl get pods -n production
        kubectl get services -n production
        kubectl get ingress -n production
        
        # Final end-to-end test
        curl -f https://austa-cockpit.com/api/health
        echo "Production deployment completed successfully"

    - name: Post deployment notification
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        fields: repo,message,commit,author,action,eventName,ref,workflow
        text: |
          Production Deployment ${{ job.status }}!
          Version: ${{ github.ref }}
          Commit: ${{ github.sha }}

  # Rollback job (manual trigger)
  rollback:
    name: Rollback Deployment  
    runs-on: ubuntu-latest
    if: failure() && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v'))
    environment:
      name: production
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Kubernetes CLI
      uses: azure/setup-kubectl@v3
      with:
        version: ${{ env.KUBERNETES_VERSION }}

    - name: Setup Helm
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Configure kubectl
      env:
        KUBE_CONFIG: ${{ secrets.KUBE_CONFIG_PRODUCTION }}
      run: |
        mkdir -p ~/.kube
        echo "$KUBE_CONFIG" | base64 -d > ~/.kube/config
        chmod 600 ~/.kube/config

    - name: Rollback to previous version
      run: |
        echo "Rolling back to previous version..."
        helm rollback austa-production -n production
        
        # Wait for rollback to complete
        kubectl rollout status deployment/austa-production-frontend -n production --timeout=300s
        kubectl rollout status deployment/austa-production-backend -n production --timeout=300s
        kubectl rollout status deployment/austa-production-ai-service -n production --timeout=300s
        
        echo "Rollback completed successfully"

    - name: Verify rollback
      run: |
        echo "Verifying rollback..."
        curl -f https://austa-cockpit.com/health || exit 1
        curl -f https://austa-cockpit.com/api/health || exit 1
        echo "Rollback verification successful"

    - name: Rollback notification
      uses: 8398a7/action-slack@v3
      with:
        status: custom
        custom_payload: |
          {
            text: "ðŸš¨ ROLLBACK EXECUTED ðŸš¨",
            attachments: [{
              color: "warning",
              fields: [{
                title: "Repository",
                value: "${{ github.repository }}",
                short: true
              }, {
                title: "Branch/Tag",
                value: "${{ github.ref }}",
                short: true
              }, {
                title: "Commit",
                value: "${{ github.sha }}",
                short: true
              }]
            }]
          }
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}